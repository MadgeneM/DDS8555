{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4458,"databundleVersionId":34321,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-----------------------------------------\n# Title:  Support Vector Machine (SVM) San Francisco Crime Classification Dataset\n# Subtitle: DDS-8555, Assignment 8\n# Author: Madgene Moise\n# Date: Sunday, July 6, 2025\n#-----------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the training and testing datasets\n\ntrain_df = pd.read_csv(\"/kaggle/input/sf-crime/train.csv.zip\") \ntest_df = pd.read_csv(\"/kaggle/input/sf-crime/test.csv.zip\")\n\n# Display the first few rows of each dataset to understand the structure\ntrain_head = train_df.head()\ntest_head = test_df.head()\n\ntrain_df.shape, test_df.shape, train_head, test_head","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:19:52.320300Z","iopub.execute_input":"2025-07-07T06:19:52.320714Z","iopub.status.idle":"2025-07-07T06:20:00.073149Z","shell.execute_reply.started":"2025-07-07T06:19:52.320681Z","shell.execute_reply":"2025-07-07T06:20:00.072072Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"((878049, 9),\n (884262, 7),\n                  Dates        Category                      Descript  \\\n 0  2015-05-13 23:53:00        WARRANTS                WARRANT ARREST   \n 1  2015-05-13 23:53:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n 2  2015-05-13 23:33:00  OTHER OFFENSES      TRAFFIC VIOLATION ARREST   \n 3  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n 4  2015-05-13 23:30:00   LARCENY/THEFT  GRAND THEFT FROM LOCKED AUTO   \n \n    DayOfWeek PdDistrict      Resolution                    Address  \\\n 0  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n 1  Wednesday   NORTHERN  ARREST, BOOKED         OAK ST / LAGUNA ST   \n 2  Wednesday   NORTHERN  ARREST, BOOKED  VANNESS AV / GREENWICH ST   \n 3  Wednesday   NORTHERN            NONE   1500 Block of LOMBARD ST   \n 4  Wednesday       PARK            NONE  100 Block of BRODERICK ST   \n \n             X          Y  \n 0 -122.425892  37.774599  \n 1 -122.425892  37.774599  \n 2 -122.424363  37.800414  \n 3 -122.426995  37.800873  \n 4 -122.438738  37.771541  ,\n    Id                Dates DayOfWeek PdDistrict                   Address  \\\n 0   0  2015-05-10 23:59:00    Sunday    BAYVIEW   2000 Block of THOMAS AV   \n 1   1  2015-05-10 23:51:00    Sunday    BAYVIEW        3RD ST / REVERE AV   \n 2   2  2015-05-10 23:50:00    Sunday   NORTHERN    2000 Block of GOUGH ST   \n 3   3  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n 4   4  2015-05-10 23:45:00    Sunday  INGLESIDE  4700 Block of MISSION ST   \n \n             X          Y  \n 0 -122.399588  37.735051  \n 1 -122.391523  37.732432  \n 2 -122.426002  37.792212  \n 3 -122.437394  37.721412  \n 4 -122.437394  37.721412  )"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"The training and test datasets from the San Francisco Crime Classification competition are structured as follows:\n\nTraining Set Summary\n* Observations: 878,049 rows\n* Columns: 9 variables\n  * Dates, Category, Descript, DayOfWeek, PdDistrict, Resolution, Address, X, Y\n \nTest Set Summary\n* Observations: 884,262 rows\n* Columns: 7 variables (no Category, Descript, or Resolution)\n  * Id, Dates, DayOfWeek, PdDistrict, Address, X, Y\n\nThe target variable is Category, which I will classify using a Support Vector Machine (SVM).","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\n\n# Sample 10% of the training data stratified by Category to balance classes\ntrain_sample, _ = train_test_split(\n    train_df, test_size=0.90, stratify=train_df['Category'], random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:20:07.798202Z","iopub.execute_input":"2025-07-07T06:20:07.798536Z","iopub.status.idle":"2025-07-07T06:20:09.581232Z","shell.execute_reply.started":"2025-07-07T06:20:07.798509Z","shell.execute_reply":"2025-07-07T06:20:09.580196Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Extract basic datetime features\ndef preprocess_dates(df):\n    df['Dates'] = pd.to_datetime(df['Dates'])\n    df['Hour'] = df['Dates'].dt.hour\n    df['Month'] = df['Dates'].dt.month\n    df['Year'] = df['Dates'].dt.year\n    df['Day'] = df['Dates'].dt.day\n    df['Weekday'] = df['Dates'].dt.weekday\n    return df\n\ntrain_sample = preprocess_dates(train_sample)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:20:26.796908Z","iopub.execute_input":"2025-07-07T06:20:26.797664Z","iopub.status.idle":"2025-07-07T06:20:26.872328Z","shell.execute_reply.started":"2025-07-07T06:20:26.797604Z","shell.execute_reply":"2025-07-07T06:20:26.871411Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Encode categorical variables\nlabel_encoders = {}\nfor col in ['DayOfWeek', 'PdDistrict']:\n    le = LabelEncoder()\n    train_sample[col] = le.fit_transform(train_sample[col])\n    label_encoders[col] = le\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:20:35.806400Z","iopub.execute_input":"2025-07-07T06:20:35.806773Z","iopub.status.idle":"2025-07-07T06:20:35.849357Z","shell.execute_reply.started":"2025-07-07T06:20:35.806747Z","shell.execute_reply":"2025-07-07T06:20:35.848394Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Encode target variable\ntarget_encoder = LabelEncoder()\ntrain_sample['Category'] = target_encoder.fit_transform(train_sample['Category'])\n\n# Select features and target\nX = train_sample[['Hour', 'Month', 'Year', 'Day', 'Weekday', 'DayOfWeek', 'PdDistrict', 'X', 'Y']]\ny = train_sample['Category']\n\nX.shape, y.shape, y.nunique()  # Number of classes in target variable","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T06:20:41.342395Z","iopub.execute_input":"2025-07-07T06:20:41.342770Z","iopub.status.idle":"2025-07-07T06:20:41.382341Z","shell.execute_reply.started":"2025-07-07T06:20:41.342745Z","shell.execute_reply":"2025-07-07T06:20:41.381576Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((87804, 9), (87804,), 39)"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"I have a stratified 10% sample of the training data with the following characteristics:\n\n* Observations: 87,804\n\n* Features Used: 9\n  * Temporal: Hour, Month, Year, Day, Weekday\n  * Categorical (encoded): DayOfWeek, PdDistrict\n  * Spatial: X, Y\n\n* Target Variable: Category (encoded into 39 unique crime categories) ","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler\n\n# Scale the features for SVM\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# Train a linear SVM classifier (using linear kernel for interpretability)\nsvm_clf = SVC(kernel='linear', C=1.0, decision_function_shape='ovr', random_state=42)\nsvm_clf.fit(X_train_scaled, y_train)\n\n# Filter out rare classes with fewer than 5 occurrences\ncategory_counts = train_sample['Category'].value_counts()\nvalid_categories = category_counts[category_counts >= 5].index\nfiltered_sample = train_sample[train_sample['Category'].isin(valid_categories)]\n\n# Redefine X and y with the filtered data\nX_filtered = filtered_sample[['Hour', 'Month', 'Year', 'Day', 'Weekday', 'DayOfWeek', 'PdDistrict', 'X', 'Y']]\ny_filtered = filtered_sample['Category']\n\n# Split again\nX_train, X_val, y_train, y_val = train_test_split(\n    X_filtered, y_filtered, test_size=0.2, stratify=y_filtered, random_state=42\n)\n\n# Scale the features\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\n\n# Train SVM again\nsvm_clf.fit(X_train_scaled, y_train)\ny_pred = svm_clf.predict(X_val_scaled)\n\n# Classification report\nreport = classification_report(y_val, y_pred, target_names=target_encoder.inverse_transform(np.unique(y_val)))\n\nreport[:1500]  # Trimmed for readability","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T00:39:38.934763Z","iopub.execute_input":"2025-07-07T00:39:38.935175Z","iopub.status.idle":"2025-07-07T01:00:08.361064Z","shell.execute_reply.started":"2025-07-07T00:39:38.935141Z","shell.execute_reply":"2025-07-07T01:00:08.359931Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Support Vector Machine (SVM) Classification**\n* Model: Linear kernel SVM (c=1.0, One-vs-Rest)\n* Classes Used: A subset of 39 crime categories (excluding those with <5 samples)\n* Evaluation: 20% holdout validation set.\n* Features Used: Date/time, location (X, Y), district, and encoded day-of-week","metadata":{}},{"cell_type":"markdown","source":"**Results**\n\nPrecision and recall vary considerably across categories because common crimes like LARCENY/THEFT, DRUG/NARCOTIC, and VEHICLE THEFT show moderate precision (~0.4 - 0.6) and recall. The rare or ambiguous categories (e.g., TREA, SEX OFFENSES FORCIBLE) typically have low recall due to underrepresentation.\n\nThe F1-score is skewed toward dominant categories because SVM struggles with an imbalanced class distribution.","metadata":{}},{"cell_type":"markdown","source":"**Assumption Checks**\n\n* Linearity: SVM with a linear kernel assumes linear class separation. The given crime data is complex; this is likely a weak assumption.\n* Feature Scaling: Addressed using StandardScaler, which is important due to spatial features.\n* Class Balance: Still skewed - SVMs are sensitive to imbalanced classes. I need to consider class weights or sampling methods to address this.","metadata":{}},{"cell_type":"code","source":"# Generate Submission Locally \nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.svm import SVC\n\n# File paths\nOUTPUT_PATH = \"/kaggle/working/svm_submission_moisem.csv\"\nBATCH_SIZE = 100000  # Controls memory usage\n\n# Preprocess datetime features\ndef preprocess_dates(df):\n    df['Dates'] = pd.to_datetime(df['Dates'])\n    df['Hour'] = df['Dates'].dt.hour\n    df['Month'] = df['Dates'].dt.month\n    df['Year'] = df['Dates'].dt.year\n    df['Day'] = df['Dates'].dt.day\n    df['Weekday'] = df['Dates'].dt.weekday\n    return df\n\ntrain_df = preprocess_dates(train_df)\ntest_df = preprocess_dates(test_df)\n\n# Stratified 1% sample\ntrain_sample, _ = train_test_split(\n    train_df, test_size=0.99, stratify=train_df['Category'], random_state=42\n)\n\n# Encode categorical variables\nlabel_encoders = {}\nfor col in ['DayOfWeek', 'PdDistrict']:\n    le = LabelEncoder()\n    combined = pd.concat([train_sample[col].astype(str), test_df[col].astype(str)], axis=0)\n    le.fit(combined)\n    train_sample[col] = le.transform(train_sample[col].astype(str))\n    test_df[col] = le.transform(test_df[col].astype(str))\n    label_encoders[col] = le\n\n# Encode target variable\ntarget_encoder = LabelEncoder()\ntrain_sample['Category'] = target_encoder.fit_transform(train_sample['Category'])\n\n# Remove rare classes (fewer than 5 samples)\ncategory_counts = train_sample['Category'].value_counts()\nvalid_classes = category_counts[category_counts >= 5].index\ntrain_sample = train_sample[train_sample['Category'].isin(valid_classes)]\n\n# Feature selection\nfeatures = ['Hour', 'Month', 'Year', 'Day', 'Weekday', 'DayOfWeek', 'PdDistrict', 'X', 'Y']\nX = train_sample[features]\ny = train_sample['Category']\n\n# Train-test split for training\nX_train, _, y_train, _ = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n\n# Scale features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\n\n# Train SVM\nsvm_clf = SVC(kernel='linear', C=1.0, decision_function_shape='ovr')\nsvm_clf.fit(X_train_scaled, y_train)\n\n# Predict test set in batches\ndef softmax(x):\n    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n    return e_x / e_x.sum(axis=1, keepdims=True)\n\nbatch_probs = []\n\nfor i in range(0, test_df.shape[0], BATCH_SIZE):\n    batch = test_df.iloc[i:i+BATCH_SIZE]\n    X_batch = batch[features]\n    X_batch_scaled = scaler.transform(X_batch)\n    decision_scores = svm_clf.decision_function(X_batch_scaled)\n    probs = softmax(decision_scores)\n    batch_probs.append(probs)\n\nprobs_combined = np.vstack(batch_probs)\n\n# Build Full 39-Class Submission Matrix\nall_labels = list(target_encoder.classes_)\npredicted_labels = target_encoder.inverse_transform(np.unique(y_train))\nfull_probs = np.zeros((probs_combined.shape[0], len(all_labels)))\nlabel_index_map = {label: i for i, label in enumerate(all_labels)}\n\nfor idx, label in enumerate(predicted_labels):\n    full_index = label_index_map[label]\n    full_probs[:, full_index] = probs_combined[:, idx]\n\nsubmission_df = pd.DataFrame(full_probs, columns=all_labels)\nsubmission_df.insert(0, 'Id', test_df['Id'])\n\n# Fix Missing Columns by Adding Zeros \nrequired_columns = ['Id'] + list(target_encoder.classes_)\nfor col in target_encoder.classes_:\n    if col not in submission_df.columns:\n        submission_df[col] = 0.0\n\nsubmission_df = submission_df[required_columns]  # Ensure correct column order\n\n# Save to CSV\nsubmission_df.to_csv(OUTPUT_PATH, index=False)\nprint(f\"Submission file saved to: {OUTPUT_PATH}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T07:09:18.274282Z","iopub.execute_input":"2025-07-07T07:09:18.274617Z","iopub.status.idle":"2025-07-07T07:18:40.415929Z","shell.execute_reply.started":"2025-07-07T07:09:18.274594Z","shell.execute_reply":"2025-07-07T07:18:40.414643Z"}},"outputs":[{"name":"stdout","text":"Submission file saved to: /kaggle/working/svm_submission_moisem.csv\n","output_type":"stream"}],"execution_count":10}]}